# Smart Media Insights Platform

A cloud-native, event-driven architecture for media upload, processing, and insights using AWS, Kubernetes, Terraform, and serverless tools.

---

## Overview

This project automates a platform that allows users to upload media files, trigger image analysis using Rekognition and natural-language processing using Comprehend, and retrieve results via a scalable APIâ€”all built with microservices, Lambdas, and managed Kubernetes (EKS).

---

## Architecture
![image](https://github.com/user-attachments/assets/1027b0a2-42bd-4cc5-8911-4259184b7a30)
- **VPC**: Multi-AZ public/private subnets, NAT gateways, and secure routing
- **IAM & KMS**: Fine-grained roles and a customer-managed encryption key
- **Storage**: Encrypted S3 buckets for uploads, DynamoDB for lookups, RDS for structured metadata
- **Streaming**: Kinesis Data Stream triggers event processing
- **Serverless**: Lambda functions connected to S3 and Kinesis
- **Containers**: Flask-based microservices containerized and deployed to EKS via Helm
- **Ingress**: Application Load Balancer (ALB) with AWS WAF and optional TLS termination

---

## Components

### 1. Infrastructure-as-Code (Terraform in `/infra`)
- Modules for:
  - VPC, EKS, RDS, IAM, Kinesis, S3, Lambda, WAF, KMS
- Uses remote backend via S3 and DynamoDB for state management

### 2. Microservices (`/services`)
- `upload_service`: Accepts files and stores them in S3
- `results_service`: Reads analysis results from RDS and serves via API

### 3. Serverless Functions (`/lambda`)
- `analyze_image`: S3-triggered Lambda that calls Rekognition
- `process_stream`: Kinesis-triggered Lambda that calls Comprehend and writes to RDS

---

## Prerequisites

| Tool           | Minimum Version |
|----------------|------------------|
| Python         | 3.8+             |
| Terraform      | 1.3+             |
| AWS CLI        | configured       |
| Docker         | latest           |
| kubectl & Helm | latest           |

AWS Resources required beforehand:
- S3 bucket for Terraform backend
- DynamoDB table for Terraform locking

---

## Setup Instructions

### 1. Clone & Initialize

```bash
git clone https://github.com/yourusername/SmartMediaInsights.git
cd SmartMediaInsights

2. Initialize Terraform
cd infra
terraform init
terraform apply
3. Build and Push Microservice Containers
# Example: Upload Service
cd services/upload_service
docker build -t upload_service:latest .
docker tag upload_service:latest <your-ecr-url>/upload_service:latest
docker push <your-ecr-url>/upload_service:latest
Repeat for results_service.

4. Deploy to EKS with Helm
helm upgrade --install upload-service services/upload_service/helm --namespace production --create-namespace
helm upgrade --install results-service services/results_service/helm --namespace production
5. Update Lambda Code (if changed)
aws lambda update-function-code \
  --function-name dev-process-stream \
  --zip-file fileb://infra/modules/lambda/process_stream.zip
How It Works
/upload â†’ Upload Service saves file to S3

S3 event â†’ Triggers analyze_image Lambda â†’ Rekognition â†’ metadata â†’ Kinesis

Kinesis â†’ Triggers process_stream Lambda â†’ Comprehend â†’ RDS

/results/{file} â†’ Results Service reads from RDS and returns insights

Testing
kubectl port-forward svc/upload-service 9090:5000 -n production
curl -X POST http://localhost:9090/upload -F file=@/path/to/image.jpg

kubectl port-forward svc/results-service 9091:5000 -n production
curl http://localhost:9091/results/image.jpg
Security & Best Practices
IAM roles with least-privilege

VPC subnet isolation

All storage encrypted (S3, RDS, Kinesis)

ALB protected by WAF

TLS-ready Ingress support

ðŸ“ Project Structure
SmartMediaInsights/
â”‚
â”œâ”€â”€ infra/                             # Terraform modules and root config
â”‚   â”œâ”€â”€ main.tf                        # Root module wiring together all infrastructure
â”‚   â”œâ”€â”€ provider.tf                    # AWS provider configuration
â”‚   â”œâ”€â”€ backend.tf                     # Remote state backend config (S3 + DynamoDB)
â”‚   â”œâ”€â”€ variables.tf                   # Shared variable declarations
â”‚   â”œâ”€â”€ outputs.tf                     # Root-level output values
â”‚   â”œâ”€â”€ terraform.tfvars               # Values for declared variables
â”‚   â””â”€â”€ modules/                       # Reusable Terraform modules
â”‚       â”œâ”€â”€ vpc/                       # Multi-AZ VPC, subnets, NAT, IGW
â”‚       â”œâ”€â”€ bastion/                   # EC2 instance for secure SSH into private subnets
â”‚       â”œâ”€â”€ eks/                       # EKS cluster and node groups
â”‚       â”œâ”€â”€ rds/                       # MySQL/PostgreSQL instance with security group
â”‚       â”œâ”€â”€ s3/                        # S3 bucket for uploads (trigger for Lambda)
â”‚       â”œâ”€â”€ kinesis/                   # Kinesis Data Stream for event ingestion
â”‚       â”œâ”€â”€ dynamodb/                  # DynamoDB table for metadata/lookup
â”‚       â”œâ”€â”€ lambda/                    # Lambda setup: IAM roles, triggers, env vars
â”‚       â”œâ”€â”€ kms/                       # Encryption key for S3/RDS/Kinesis
â”‚       â”œâ”€â”€ iam/                       # IAM roles/policies for EKS, Lambda, Terraform
â”‚       â”œâ”€â”€ waf/                       # WAF rules attached to ALB
â”‚       â””â”€â”€ security/                  # Security groups for EKS, Lambda, RDS, etc.
â”‚
â”œâ”€â”€ services/                          # Flask microservices + Docker + Helm
â”‚   â”œâ”€â”€ upload_service/                # Service to upload files to S3
â”‚   â”‚   â”œâ”€â”€ app.py                     # Flask app
â”‚   â”‚   â”œâ”€â”€ Dockerfile                 # Docker container definition
â”‚   â”‚   â””â”€â”€ helm/                      # Helm chart for EKS deployment
â”‚   â”‚       â”œâ”€â”€ Chart.yaml
â”‚   â”‚       â”œâ”€â”€ values.yaml
â”‚   â”‚       â””â”€â”€ templates/
â”‚   â”‚           â”œâ”€â”€ deployment.yaml
â”‚   â”‚           â”œâ”€â”€ service.yaml
â”‚   â”‚           â””â”€â”€ ingress.yaml
â”‚   â”‚
â”‚   â””â”€â”€ results_service/               # Service to fetch file analysis from RDS
â”‚       â”œâ”€â”€ app.py
â”‚       â”œâ”€â”€ Dockerfile
â”‚       â””â”€â”€ helm/
â”‚           â”œâ”€â”€ Chart.yaml
â”‚           â”œâ”€â”€ values.yaml
â”‚           â””â”€â”€ templates/
â”‚               â”œâ”€â”€ deployment.yaml
â”‚               â”œâ”€â”€ service.yaml
â”‚               â””â”€â”€ ingress.yaml
â”‚
â”œâ”€â”€ lambda/                            # AWS Lambda functions
â”‚   â”œâ”€â”€ analyze_image/                 # Triggered by S3 -> calls Rekognition
â”‚   â”‚   â”œâ”€â”€ handler.py                 # Main Lambda logic
â”‚   â”‚   â””â”€â”€ analyze_image.zip          # Deployment package
â”‚   â”‚
â”‚   â””â”€â”€ process_stream/                # Triggered by Kinesis -> calls Comprehend
â”‚       â”œâ”€â”€ handler.py
â”‚       â”œâ”€â”€ process_stream.zip
â”‚       â””â”€â”€ package/                   # Dependencies (e.g., pymysql)
â”‚           â”œâ”€â”€ pymysql/
â”‚           â””â”€â”€ ...
â”‚
â””â”€â”€ README.md                          # Project overview and deployment instructions
